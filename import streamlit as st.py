import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.figure_factory as ff
from datetime import datetime, timedelta
import scipy.stats as stats
import warnings
import sys
import os
from contextlib import contextmanager
warnings.filterwarnings('ignore')
import sys

# Optional imports with fallbacks
try:
    from lifelines import KaplanMeierFitter
    from lifelines.statistics import logrank_test
    SURVIVAL_ANALYSIS = True
except ImportError:
    SURVIVAL_ANALYSIS = False

try:
    import networkx as nx
    NETWORK_ANALYSIS = True
except ImportError:
    NETWORK_ANALYSIS = False

try:
    from features import (
        create_learning_dashboard_data,
        generate_learning_recommendations,
        LearningIntelligenceEngine,
        get_learning_velocity,
        get_network_data,
        get_difficulty_stats
    )
    FEATURES_AVAILABLE = True
except ImportError:
    FEATURES_AVAILABLE = False

# Page Configuration
st.set_page_config(
    page_title="EduAnalytics Dashboard",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Context manager for suppressing output safely
@contextmanager
def suppress_stdout():
    """Safely suppress stdout with proper encoding handling"""
    try:
        with open(os.devnull, 'w', encoding='utf-8') as devnull:
            old_stdout = sys.stdout
            sys.stdout = devnull
            yield
    except:
        # If devnull fails, just continue without suppressing
        yield
    finally:
        if 'old_stdout' in locals():
            sys.stdout = old_stdout

# Modern CSS Styling
st.markdown("""
<style>
    /* Main Header */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 20px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
    }
    
    /* Professional Metric Cards */
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        border-left: 4px solid #667eea;
        transition: transform 0.3s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 30px rgba(0, 0, 0, 0.15);
    }
    
    .metric-value {
        font-size: 2.5rem;
        font-weight: 700;
        color: #2c3e50;
        margin: 0;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #7f8c8d;
        margin: 0.5rem 0;
        font-weight: 500;
    }
    
    .metric-delta {
        font-size: 0.8rem;
        padding: 0.2rem 0.5rem;
        border-radius: 20px;
        font-weight: 500;
    }
    
    .delta-positive {
        background: #d4edda;
        color: #155724;
    }
    
    .delta-negative {
        background: #f8d7da;
        color: #721c24;
    }
    
    /* Insight Cards */
    .insight-card {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        border-left: 4px solid #28a745;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
    }
    
    .insight-title {
        color: #2c3e50;
        font-size: 1.1rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }
    
    .insight-text {
        color: #495057;
        font-size: 0.9rem;
        line-height: 1.5;
    }
    
    /* Navigation Pills */
    .nav-pills {
        background: #f8f9fa;
        padding: 0.5rem;
        border-radius: 25px;
        margin-bottom: 2rem;
    }
    
    /* Chart Containers */
    .chart-container {
        background: white;
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.08);
        margin-bottom: 1.5rem;
    }
    
    /* Advanced Analytics Toggle */
    .advanced-toggle {
        background: linear-gradient(135deg, #6c5ce7 0%, #a29bfe 100%);
        color: white;
        padding: 1rem;
        border-radius: 15px;
        margin: 1rem 0;
        text-align: center;
    }
    
    /* Recommendation Cards */
    .recommendation-card {
        background: linear-gradient(135deg, #00b894 0%, #00cec9 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    }
    
    /* Status Badges */
    .status-badge {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 500;
        margin: 0.2rem;
    }
    
    .status-excellent {
        background: #d4edda;
        color: #155724;
    }
    
    .status-good {
        background: #d1ecf1;
        color: #0c5460;
    }
    
    .status-warning {
        background: #fff3cd;
        color: #856404;
    }
    
    .status-poor {
        background: #f8d7da;
        color: #721c24;
    }
    
    /* Sidebar Styling */
    .sidebar-metric {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 3px solid #667eea;
    }
    
    /* Footer */
    .dashboard-footer {
        background: linear-gradient(135deg, #2d3436 0%, #636e72 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-top: 3rem;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

# Header
st.markdown("""
<div class="main-header">
    <h1>üéì EduAnalytics Intelligence Dashboard</h1>
    <p>Data-Driven Insights for Educational Excellence</p>
</div>
""", unsafe_allow_html=True)

# === Standardize Columns ===
def standardize_column_names(df):
    column_mapping = {}
    important_columns = [
        'engagement_score', 'rating', 'views', 'likes', 'comments', 
        'enrollments', 'upvotes', 'upvote_ratio', 'comments_per_minute',
        'likes_per_minute', 'educational_score', 'complexity_score',
        'discussion_engagement', 'engagement_rate', 'gilded',
        'engagement_score_normalized', 'engagement_category', 'course_title'
    ]
    for col in important_columns:
        if f"{col}_course" in df.columns and f"{col}_engagement" in df.columns:
            if col.startswith('engagement') or col in ['rating', 'views', 'likes', 'comments']:
                column_mapping[col] = f"{col}_engagement"
            else:
                column_mapping[col] = f"{col}_course"
        elif f"{col}_course" in df.columns:
            column_mapping[col] = f"{col}_course"
        elif f"{col}_engagement" in df.columns:
            column_mapping[col] = f"{col}_engagement"
        elif col in df.columns:
            column_mapping[col] = col
    
    for standard_name, actual_name in column_mapping.items():
        if actual_name in df.columns and standard_name not in df.columns:
            df[standard_name] = df[actual_name]
    
    return df

# Enhanced Learning Efficiency Function
def add_derived_columns(df):
    """
    Add derived columns including robust learning efficiency calculation
    """
    # Learning Efficiency with multiple fallback strategies
    if 'completion_rate' in df.columns and 'duration_minutes' in df.columns:
        # Primary calculation: completion rate normalized by duration
        df['learning_efficiency'] = (
            df['completion_rate'].fillna(0) /
            (df['duration_minutes'].fillna(60) / 60).clip(lower=0.1)
        )
    elif 'engagement_score' in df.columns and 'educational_score' in df.columns:
        # Secondary calculation: engagement * educational score
        df['learning_efficiency'] = (
            df['engagement_score'].fillna(0) * df['educational_score'].fillna(0)
        )
    elif 'engagement_score' in df.columns:
        # Tertiary calculation: normalized engagement score
        df['learning_efficiency'] = df['engagement_score'].fillna(0) / 100
    else:
        # Fallback: random values for demonstration
        df['learning_efficiency'] = np.random.uniform(0.001, 0.01, len(df))
    
    # Additional derived metrics
    if 'rating' in df.columns and 'engagement_score' in df.columns:
        df['quality_index'] = (df['rating'] * 0.4 + df['engagement_score'] * 0.6)
    
    if 'views' in df.columns and 'likes' in df.columns:
        df['popularity_score'] = np.log1p(df['views']) + np.log1p(df['likes'])
    
    # Create engagement categories if engagement_score exists
    if 'engagement_score' in df.columns:
        df['engagement_category'] = pd.cut(df['engagement_score'], 
                                         bins=[0, 0.3, 0.6, 0.8, 1.0], 
                                         labels=['Low', 'Medium', 'High', 'Excellent'])
    
    return df

# Data Loading Functions
def create_advanced_fallback_data():
    """Create sophisticated fallback data with statistical properties"""
    np.random.seed(42)
    
    subjects = ['Data Science', 'Machine Learning', 'Programming', 'Statistics', 'Business Analytics', 'AI/ML']
    difficulties = ['Beginner', 'Intermediate', 'Advanced']
    platforms = ['YouTube', 'Coursera', 'Udemy', 'edX']
    instructors = ['Dr. Sarah Chen', 'Prof. Michael Rodriguez', 'Dr. Emily Johnson', 'Prof. David Kim', 'Dr. Lisa Wang']
    
    n_courses = 350
    base_quality = np.random.normal(0.7, 0.2, n_courses)
    base_engagement = np.clip(base_quality + np.random.normal(0, 0.1, n_courses), 0, 1)
    
    data = {
        'course_id': [f'course_{i:04d}' for i in range(n_courses)],
        'title': [f'{np.random.choice(subjects)} - {np.random.choice(["Fundamentals", "Advanced", "Masterclass", "Bootcamp"])}' for _ in range(n_courses)],
        'instructor': np.random.choice(instructors, n_courses),
        'category': np.random.choice(subjects, n_courses),
        'difficulty_level': np.random.choice(difficulties, n_courses),
        'platform': np.random.choice(platforms, n_courses),
        'duration_minutes': np.random.lognormal(4, 0.5, n_courses).astype(int),
        'rating': np.clip(base_quality * 5, 1, 5),
        'views': np.random.lognormal(6, 1.5, n_courses).astype(int),
        'likes': np.random.lognormal(4, 1, n_courses).astype(int),
        'comments': np.random.lognormal(3, 1, n_courses).astype(int),
        'enrollments': np.random.lognormal(5, 1, n_courses).astype(int),
        'completion_rate': np.clip(base_engagement, 0.1, 0.95),
        'engagement_score': base_engagement,
        'price': np.random.choice([0, 29, 49, 99, 199], n_courses, p=[0.3, 0.2, 0.2, 0.2, 0.1]),
        'is_free': np.random.choice([True, False], n_courses, p=[0.3, 0.7]),
        'published_at': pd.date_range('2023-01-01', periods=n_courses, freq='3H'),
        'last_updated': pd.date_range('2023-06-01', periods=n_courses, freq='5H'),
        'dropout_time': np.random.exponential(30, n_courses),
        'complexity_score': np.random.beta(2, 3, n_courses),
    }
    return pd.DataFrame(data)

@st.cache_data(ttl=3600)  # Cache for 1 hour
def load_advanced_data():
    """Load data with preprocessing and enhanced derived columns"""
    with st.spinner("Loading data..."):
        try:
            if FEATURES_AVAILABLE:
                engine = LearningIntelligenceEngine()
                
                # Use the safe context manager to suppress verbose output
                with suppress_stdout():
                    success = engine.load_enhanced_data()
                
                if success and hasattr(engine, 'completion_df') and engine.completion_df is not None:
                    df = engine.completion_df.copy()
                    st.success(f"‚úÖ Loaded {len(df)} courses from database")
                else:
                    df = create_advanced_fallback_data()
                    st.info("‚ÑπÔ∏è Using synthetic data for demonstration")
            else:
                df = create_advanced_fallback_data()
                st.info("‚ÑπÔ∏è Using synthetic data (features module not available)")
        
        except Exception as e:
            # Use ASCII characters to avoid encoding issues
            error_msg = str(e).encode('ascii', errors='ignore').decode('ascii')
            st.error(f"‚ö†Ô∏è Error loading data: {error_msg}")
            df = create_advanced_fallback_data()
            st.info("‚ÑπÔ∏è Switched to fallback data")
        
        # Apply transformations
        df = standardize_column_names(df)
        df = add_derived_columns(df)
        
        # Data quality improvements
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            df[col] = df[col].fillna(df[col].median())  # Use median instead of mean
        
        return df

# Load data
with st.spinner("üîÑ Loading analytics data..."):
    df = load_advanced_data()

# Sidebar Navigation
st.sidebar.markdown("### üìä Dashboard Navigation")
main_view = st.sidebar.radio(
    "Select View",
    ["üéì Learning Insights", "üìä Content & Platform", "üß† Advanced Analytics"],
    index=0
)

# Sidebar Metrics Summary
st.sidebar.markdown("---")
st.sidebar.markdown("### üìà Key Metrics")

total_courses = len(df)
avg_completion = df['completion_rate'].mean()
avg_rating = df['rating'].mean()
top_platform = df['platform'].value_counts().index[0]

st.sidebar.markdown(f"""
<div class="sidebar-metric">
    <strong>{total_courses:,}</strong><br>
    <small>Total Courses</small>
</div>
<div class="sidebar-metric">
    <strong>{avg_completion:.1%}</strong><br>
    <small>Avg Completion</small>
</div>
<div class="sidebar-metric">
    <strong>{avg_rating:.1f}/5</strong><br>
    <small>Avg Rating</small>
</div>
<div class="sidebar-metric">
    <strong>{top_platform}</strong><br>
    <small>Top Platform</small>
</div>
""", unsafe_allow_html=True)

# Main Dashboard Content
if main_view == "üéì Learning Insights":
    st.header("üéì Learning Performance Insights")
    
    # Key Metrics Row
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        completion_rate = df['completion_rate'].mean()
        completion_delta = "+5.2%" if completion_rate > 0.5 else "-2.1%"
        delta_class = "delta-positive" if completion_rate > 0.5 else "delta-negative"
        
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{completion_rate:.1%}</div>
            <div class="metric-label">Completion Rate</div>
            <div class="metric-delta {delta_class}">{completion_delta}</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        avg_duration = df['duration_minutes'].mean()
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{avg_duration:.0f}m</div>
            <div class="metric-label">Avg Duration</div>
            <div class="metric-delta delta-positive">Optimal</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        learning_efficiency = df['learning_efficiency'].mean()
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{learning_efficiency:.3f}</div>
            <div class="metric-label">Learning Efficiency</div>
            <div class="metric-delta delta-positive">+12.3%</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        quality_score = df['quality_index'].mean()
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{quality_score:.2f}</div>
            <div class="metric-label">Quality Index</div>
            <div class="metric-delta delta-positive">High</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Charts Row
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        
        # Completion by Difficulty
        completion_by_difficulty = df.groupby('difficulty_level')['completion_rate'].mean()
        fig = px.bar(x=completion_by_difficulty.index, y=completion_by_difficulty.values,
                    title="üìä Completion Rate by Difficulty Level",
                    color=completion_by_difficulty.values,
                    color_continuous_scale="viridis")
        fig.update_layout(showlegend=False, height=350)
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        
        # Engagement Distribution
        fig = px.histogram(df, x='engagement_score', nbins=20,
                          title="üìà Engagement Score Distribution",
                          color_discrete_sequence=['#667eea'])
        fig.update_layout(showlegend=False, height=350)
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Insights Row
    col1, col2 = st.columns(2)
    
    with col1:
        # Top performing categories
        top_categories = df.groupby('category')['completion_rate'].mean().sort_values(ascending=False).head(3)
        
        insights_text = ""
        for i, (cat, rate) in enumerate(top_categories.items()):
            insights_text += f"‚Ä¢ {cat}: {rate:.1%}<br>"
        
        st.markdown(f"""
        <div class="insight-card">
            <div class="insight-title">üéØ Top Performing Categories</div>
            <div class="insight-text">{insights_text}</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        # Optimal duration insight
        high_completion = df[df['completion_rate'] > df['completion_rate'].quantile(0.8)]
        optimal_duration = high_completion['duration_minutes'].median()
        
        st.markdown(f"""
        <div class="insight-card">
            <div class="insight-title">‚è±Ô∏è Optimal Course Duration</div>
            <div class="insight-text">
                High-completion courses average <strong>{optimal_duration:.0f} minutes</strong><br>
                Sweet spot: 30-60 minutes for maximum retention
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # Recommendations
    st.markdown(f"""
    <div class="recommendation-card">
        <h4>üéØ Key Recommendations</h4>
        <p><strong>Duration Strategy:</strong> Target {optimal_duration:.0f}-minute courses for optimal completion</p>
        <p><strong>Content Focus:</strong> {top_categories.index[0]} shows highest completion rates</p>
        <p><strong>Engagement:</strong> {(df['engagement_score'] > 0.7).sum()} courses exceed engagement threshold</p>
    </div>
    """, unsafe_allow_html=True)

elif main_view == "üìä Content & Platform":
    st.header("üìä Content & Platform Analytics")
    
    # Platform Performance Metrics
    col1, col2, col3, col4 = st.columns(4)
    
    platform_stats = df.groupby('platform').agg({
        'views': 'sum',
        'rating': 'mean',
        'completion_rate': 'mean',
        'enrollments': 'sum'
    }).round(2)
    
    with col1:
        total_views = df['views'].sum()
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{total_views:,}</div>
            <div class="metric-label">Total Views</div>
            <div class="metric-delta delta-positive">+18.5%</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        avg_rating = df['rating'].mean()
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{avg_rating:.1f}/5</div>
            <div class="metric-label">Average Rating</div>
            <div class="metric-delta delta-positive">+0.3</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        total_enrollments = df['enrollments'].sum()
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{total_enrollments:,}</div>
            <div class="metric-label">Total Enrollments</div>
            <div class="metric-delta delta-positive">+22.1%</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        platforms_count = df['platform'].nunique()
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{platforms_count}</div>
            <div class="metric-label">Platforms</div>
            <div class="metric-delta delta-positive">Active</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Platform Comparison Charts
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        
        # Platform Market Share
        market_share = df.groupby('platform')['views'].sum().sort_values(ascending=False)
        fig = px.pie(values=market_share.values, names=market_share.index,
                    title="üì∫ Platform Market Share (by Views)")
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        
        # Platform Performance Radar
        platform_metrics = df.groupby('platform').agg({
            'rating': 'mean',
            'completion_rate': 'mean',
            'engagement_score': 'mean'
        }).round(3)
        
        fig = go.Figure()
        for platform in platform_metrics.index:
            fig.add_trace(go.Scatterpolar(
                r=[platform_metrics.loc[platform, 'rating']/5,
                   platform_metrics.loc[platform, 'completion_rate'],
                   platform_metrics.loc[platform, 'engagement_score']],
                theta=['Rating', 'Completion', 'Engagement'],
                fill='toself',
                name=platform
            ))
        
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
            title="üéØ Platform Performance Comparison",
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Content Analysis
    st.markdown('<div class="chart-container">', unsafe_allow_html=True)
    
    # Category Performance Matrix
    fig = px.scatter(df, x='duration_minutes', y='completion_rate',
                    size='views', color='category',
                    title="üìä Content Performance Matrix: Duration vs Completion",
                    hover_data=['rating', 'engagement_score'])
    fig.update_layout(height=500)
    st.plotly_chart(fig, use_container_width=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Platform Status Cards
    st.subheader("üèÜ Platform Performance Status")
    
    cols = st.columns(len(platform_stats))
    
    for i, (platform, stats) in enumerate(platform_stats.iterrows()):
        with cols[i]:
            # Determine status based on performance
            rating_score = stats['rating']
            completion_score = stats['completion_rate']
            
            if rating_score >= 4.0 and completion_score >= 0.6:
                status = "status-excellent"
                status_text = "Excellent"
            elif rating_score >= 3.5 and completion_score >= 0.4:
                status = "status-good"
                status_text = "Good"
            elif rating_score >= 3.0 and completion_score >= 0.3:
                status = "status-warning"
                status_text = "Needs Improvement"
            else:
                status = "status-poor"
                status_text = "Poor"
            
            st.markdown(f"""
            <div class="insight-card">
                <div class="insight-title">{platform}</div>
                <div class="insight-text">
                    <span class="status-badge {status}">{status_text}</span><br>
                    <strong>Rating:</strong> {stats['rating']:.1f}/5<br>
                    <strong>Completion:</strong> {stats['completion_rate']:.1%}<br>
                    <strong>Views:</strong> {stats['views']:,}
                </div>
            </div>
            """, unsafe_allow_html=True)
elif main_view == "üß† Advanced Analytics":
    st.header("üß† Advanced Statistical Analytics")
    
    # Get backend difficulty statistics
    difficulty_stats = get_difficulty_stats()
    
    st.subheader("üìä Statistical Analysis")
    
    # Multiple Statistical Tests
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üéØ Duration Analysis (Kruskal-Wallis)")
        
        # Backend's Kruskal-Wallis test for duration
        backend_tests = difficulty_stats.get('tests', {})
        duration_test = backend_tests.get('duration_difference', {})
        
        if duration_test:
            test_name = duration_test.get('test', 'Kruskal-Wallis')
            h_stat = duration_test.get('statistic', 0)
            p_value = duration_test.get('p_value', 1)
            significant = duration_test.get('significant', False)
            
            significance_text = "Significant" if significant else "Not Significant"
            significance_color = "green" if significant else "red"
            
            st.markdown(f"""
            <div class="insight-card">
                <div class="insight-title">üìà {test_name}: Difficulty vs Duration</div>
                <div class="insight-text">
                    <strong>H-statistic:</strong> {h_stat:.3f}<br>
                    <strong>P-value:</strong> {p_value:.4f}<br>
                    <strong>Result:</strong> <span style="color: {significance_color}">{significance_text}</span><br>
                    <small>Tests if course duration differs significantly across difficulty levels</small>
                </div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("‚ö†Ô∏è Duration statistical test not available - insufficient data")
    
    with col2:
        st.markdown("### üìä Engagement Analysis (ANOVA)")
        
        # Frontend ANOVA test for engagement
        if 'engagement_score' in df.columns and 'difficulty_level' in df.columns:
            # Filter out missing data
            valid_data = df.dropna(subset=['engagement_score', 'difficulty_level'])
            
            if len(valid_data) > 0:
                groups = [group['engagement_score'].values 
                         for name, group in valid_data.groupby('difficulty_level')
                         if len(group) >= 3]  # Minimum 3 samples per group
                
                if len(groups) >= 2:
                    try:
                        f_stat, p_value = stats.f_oneway(*groups)
                        significance = "Significant" if p_value < 0.05 else "Not Significant"
                        significance_color = "green" if p_value < 0.05 else "red"
                        
                        st.markdown(f"""
                        <div class="insight-card">
                            <div class="insight-title">üéØ ANOVA: Difficulty vs Engagement</div>
                            <div class="insight-text">
                                <strong>F-statistic:</strong> {f_stat:.3f}<br>
                                <strong>P-value:</strong> {p_value:.4f}<br>
                                <strong>Result:</strong> <span style="color: {significance_color}">{significance}</span><br>
                                <small>Tests if engagement differs significantly across difficulty levels</small>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                    except Exception as e:
                        st.error(f"‚ùå ANOVA test failed: {str(e)}")
                else:
                    st.warning("‚ö†Ô∏è Insufficient groups for ANOVA test")
            else:
                st.warning("‚ö†Ô∏è No valid engagement data available")
        else:
            st.warning("‚ö†Ô∏è Required columns not found for engagement analysis")
    
    # Visualization Section
    st.subheader("üìà Statistical Visualizations")
    
    viz_col1, viz_col2 = st.columns(2)
    
    with viz_col1:
        # Duration distribution by difficulty (matches backend analysis)
        if 'duration_minutes' in df.columns and 'difficulty_level' in df.columns:
            fig_duration = px.box(df, x='difficulty_level', y='duration_minutes',
                                title="‚è±Ô∏è Course Duration by Difficulty Level",
                                labels={'duration_minutes': 'Duration (minutes)', 
                                       'difficulty_level': 'Difficulty Level'})
            fig_duration.update_layout(height=350)
            st.plotly_chart(fig_duration, use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è Duration data not available for visualization")
    
    with viz_col2:
        # Engagement distribution by difficulty
        if 'engagement_score' in df.columns and 'difficulty_level' in df.columns:
            fig_engagement = px.box(df, x='difficulty_level', y='engagement_score',
                                  title="üìä Engagement Distribution by Difficulty",
                                  labels={'engagement_score': 'Engagement Score', 
                                         'difficulty_level': 'Difficulty Level'})
            fig_engagement.update_layout(height=350)
            st.plotly_chart(fig_engagement, use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è Engagement data not available for visualization")
    
    # Correlation Analysis
    st.subheader("üîó Correlation Analysis")
    
    numeric_cols = ['duration_minutes', 'rating', 'engagement_score', 'completion_rate', 'views']
    available_cols = [col for col in numeric_cols if col in df.columns]
    
    if len(available_cols) > 1:
        corr_matrix = df[available_cols].corr()
        
        fig = px.imshow(corr_matrix, 
                       text_auto=True,
                       aspect="auto",
                       title="üîç Feature Correlation Matrix",
                       color_continuous_scale="RdBu")
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    
    # Advanced Insights - Survival Analysis
    with st.expander("üìà Survival Analysis", expanded=False):
        try:
            velocity_data = get_learning_velocity()
            
            if velocity_data and velocity_data.get('median_completion_time') != 'N/A':
                st.info("Survival analysis shows course completion probability over time")
                
                # Overall Survival Metrics
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(
                        "Median Completion Time", 
                        f"{velocity_data.get('median_completion_time', 'N/A')} days"
                    )
                with col2:
                    st.metric(
                        "30-Day Completion Rate", 
                        f"{velocity_data.get('completion_rate_30_days', 0):.1%}"
                    )
                with col3:
                    st.metric(
                        "60-Day Completion Rate", 
                        f"{velocity_data.get('completion_rate_60_days', 0):.1%}"
                    )
                
                # Platform Survival Comparison
                platform_comparison = velocity_data.get('platform_comparison', {})
                if platform_comparison:
                    st.subheader("Platform Survival Comparison")
                    
                    # Create comparison table
                    survival_df = pd.DataFrame([
                        {
                            'Platform': platform,
                            'Median Survival (days)': data.get('median_survival_time', 'N/A'),
                            '30-Day Survival': f"{data.get('survival_at_30_days', 0):.1%}",
                            '60-Day Survival': f"{data.get('survival_at_60_days', 0):.1%}",
                            'Total Courses': data.get('total_courses', 0),
                            'Avg Completion': f"{data.get('average_completion_rate', 0):.1%}"
                        }
                        for platform, data in platform_comparison.items()
                    ])
                    
                    st.dataframe(survival_df, use_container_width=True)
                    
                    # Survival Insights
                    st.subheader("Key Survival Insights")
                    insights = []
                    
                    # Best performing platform
                    if platform_comparison:
                        best_platform = max(platform_comparison.items(), 
                                          key=lambda x: x[1].get('survival_at_30_days', 0))
                        insights.append(f"üèÜ **{best_platform[0]}** has the highest 30-day survival rate at {best_platform[1].get('survival_at_30_days', 0):.1%}")
                        
                        # Worst performing platform
                        worst_platform = min(platform_comparison.items(), 
                                           key=lambda x: x[1].get('survival_at_30_days', 0))
                        insights.append(f"‚ö†Ô∏è **{worst_platform[0]}** has the lowest 30-day survival rate at {worst_platform[1].get('survival_at_30_days', 0):.1%}")
                    
                    # Overall completion insights
                    overall_30_day = velocity_data.get('completion_rate_30_days', 0)
                    if overall_30_day > 0.7:
                        insights.append("‚úÖ Strong 30-day completion rate indicates good course engagement")
                    elif overall_30_day < 0.3:
                        insights.append("‚ùå Low 30-day completion rate suggests need for course improvements")
                    
                    for insight in insights:
                        st.markdown(insight)
                        
            else:
                st.warning("Survival analysis data not available. This requires completion time data.")
                
        except Exception as e:
            st.error(f"Error displaying survival analysis: {str(e)}")
            st.info("Survival analysis requires proper course completion data")
    
    # Network Analysis
    with st.expander("üîó Network Analysis", expanded=False):
        try:
            network_data = get_network_data()
            
            if network_data and network_data.get('nodes', 0) > 0:
                # Quick Overview
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Courses", network_data.get('nodes', 0))
                with col2:
                    st.metric("Connections", network_data.get('edges', 0))
                with col3:
                    network_metrics = network_data.get('network_metrics', {})
                    density = network_metrics.get('density', 0)
                    st.metric("Density", f"{density:.1%}")
                
                # Network Insights
                st.markdown("""
                ### üîç Network Insights
                
                **Current Status:**
                - Your course network has **low connectivity** (0.7% density)
                - There are **20 disconnected components** - courses that don't connect to each other
                - The largest connected group has **42 courses**
                
                **What this means:**
                - Students may struggle to find clear learning paths
                - Many courses exist in isolation without prerequisites
                - Limited guidance for course progression
                
                **Recommendations:**
                1. **Add Prerequisites** - Connect related courses with clear prerequisites
                2. **Create Bridge Courses** - Develop courses that connect different topics
                3. **Establish Learning Tracks** - Group courses into coherent learning paths
                """)
                
                # Show learning paths
                optimal_paths = network_data.get('optimal_paths', {})
                if optimal_paths:
                    st.markdown("**Top Learning Paths Found:**")
                    for category, path_data in list(optimal_paths.items())[:3]:
                        paths = path_data.get('paths', [])
                        if paths:
                            st.markdown(f"**{category.title()}:** {len(paths)} learning path(s) identified")
                else:
                    st.info("No clear learning paths identified yet")
                    
            else:
                st.warning("‚ö†Ô∏è Network data not available")
                st.markdown("""
                ### üîß Network Analysis Setup
                
                Network analysis requires:
                - Course prerequisite relationships
                - Category-based course groupings
                - Difficulty level mappings
                
                Once this data is available, you'll see:
                - Interactive network graph
                - Learning path recommendations
                - Course connectivity insights
                """)
                
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")
            st.info("Network analysis temporarily unavailable")
    
    # Performance Metrics
    with st.expander("‚ö° System Performance", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Data Points", f"{len(df):,}")
        
        with col2:
            st.metric("Features", f"{len(df.columns)}")
        
        with col3:
            memory_mb = sys.getsizeof(df) / (1024 ** 2)
            st.metric("Memory Usage", f"{memory_mb:.1f} MB")
    
    # Test Assumptions and Recommendations
    st.subheader("üìã Statistical Test Assumptions & Recommendations")
    
    with st.expander("üîç Understanding the Statistical Tests"):
        st.markdown("""
        ### üéØ Kruskal-Wallis Test (Backend)
        - **Purpose**: Tests if course duration differs significantly across difficulty levels
        - **Assumptions**: 
          - Independent observations
          - Similar distribution shapes across groups
          - Ordinal or continuous data
        - **Interpretation**: 
          - p < 0.05: Significant differences in duration across difficulty levels
          - p ‚â• 0.05: No significant differences detected
        
        ### üìä ANOVA Test (Frontend)
        - **Purpose**: Tests if engagement scores differ significantly across difficulty levels
        - **Assumptions**:
          - Normal distribution within groups
          - Equal variances across groups
          - Independent observations
        - **Interpretation**:
          - p < 0.05: Significant differences in engagement across difficulty levels
          - p ‚â• 0.05: No significant differences detected
        
        ### üí° Recommendations
        - Use Kruskal-Wallis when data is not normally distributed
        - Use ANOVA when assumptions are met
        - Consider effect size in addition to p-values
        - Validate results with domain knowledge
        """)

# Footer
st.markdown("""
<div class="dashboard-footer">
    <h4>üéì EduAnalytics Dashboard</h4>
    <p>Powered by Advanced Analytics ‚Ä¢ Statistical Testing ‚Ä¢ Machine Learning</p>
    <p>¬© 2024 EduAnalytics - Transforming Education Through Data</p>
</div>
""", unsafe_allow_html=True)